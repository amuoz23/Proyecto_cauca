{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis espacio temporal de la dinámica del delito en el territorio colombiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el conjunto de datos, limpia filas irrelevantes, ajusta formatos de fechas y textos, convierte los valores numéricos a enteros y elimina una columna innecesaria, todo para preparar los datos de manera más consistente y uniforme antes de analizarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monte\\AppData\\Local\\Temp\\ipykernel_19716\\706594315.py:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Datos2010-2015.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DEPARTAMENTO     MUNICIPIO CODIGO_DANE FECHA_HECHO     GENERO  \\\n",
      "0     AMAZONAS  LETICIA (CT)    91001000  2010-01-01  MASCULINO   \n",
      "1     AMAZONAS  LETICIA (CT)    91001000  2010-01-01  MASCULINO   \n",
      "2     AMAZONAS  LETICIA (CT)    91001000  2010-01-01  MASCULINO   \n",
      "3     AMAZONAS  LETICIA (CT)    91001000  2010-01-02  MASCULINO   \n",
      "4     AMAZONAS  LETICIA (CT)    91001000  2010-01-02  MASCULINO   \n",
      "\n",
      "                        DESCRIPCION_CONDUCTA_CAPTURA GRUPO_ETARIO  CANTIDAD   \n",
      "0    ARTÍCULO 429. VIOLENCIA CONTRA SERVIDOR PÚBLICO      ADULTOS          1  \n",
      "1  ARTÍCULO 376. TRÁFICO. FABRICACIÓN O PORTE DE ...      ADULTOS          1  \n",
      "2                  ARTÍCULO 111. LESIONES PERSONALES      ADULTOS          2  \n",
      "3                    ARTÍCULO 239. HURTO RESIDENCIAS      ADULTOS          1  \n",
      "4  ARTÍCULO 376. TRÁFICO. FABRICACIÓN O PORTE DE ...      ADULTOS          1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV (ajusta el nombre y ruta del archivo)\n",
    "df = pd.read_csv('Datos2010-2015.csv')\n",
    "\n",
    "# Suponiendo que la columna se llama 'fecha'\n",
    "# Convertir de string a datetime con formato original\n",
    "df['FECHA_HECHO'] = pd.to_datetime(df['FECHA_HECHO'], format='%Y-%m-%d')\n",
    "\n",
    "# Luego convertirlo al formato YYYY-MM-DD como string\n",
    "df['FECHA_HECHO'] = df['FECHA_HECHO'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Verifica los cambios\n",
    "print(df.head())\n",
    "\n",
    "# (Opcional) Guardar en un nuevo CSV\n",
    "df.to_csv('Datos2010-2015.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data into a DataFrame\n",
    "general_data = pd.read_csv('Datos2010-2015.csv', low_memory=False)\n",
    "\n",
    "# Remove spurious rows based on 'DEPARTAMENTO'\n",
    "general_data = general_data[~general_data[\"DEPARTAMENTO\"].isin([\"QUITO\", \"MADRID\", \"NEW YORK\", \"NEW JERSEY\", \"FLORIDA\"])]\n",
    "\n",
    "# Convert 'FECHA_HECHO' column to datetime format\n",
    "general_data['FECHA_HECHO'] = pd.to_datetime(general_data['FECHA_HECHO'], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Convert all string columns to uppercase\n",
    "str_cols = general_data.select_dtypes(include=['object']).columns\n",
    "general_data[str_cols] = general_data[str_cols].apply(lambda x: x.str.upper())\n",
    "\n",
    "# Select numeric columns\n",
    "num_cols = general_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Convert numeric columns to integer type\n",
    "general_data[num_cols] = general_data[num_cols].astype(int)\n",
    "\n",
    "# Drop the 'CODIGO_DANE' column\n",
    "general_data.drop(columns=[\"CODIGO_DANE\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para reemplazar valores en una columna del conjunto de datos cuando su frecuencia es menor a un determinado percentil. La función toma el DataFrame original, calcula el percentil de las frecuencias de la columna indicada y reemplaza esos valores por un valor especificado, devolviendo una copia del DataFrame con las modificaciones.</br> **Es usado para evitar listar crimenes poco relevantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def replace_by_percentile(data, column, percentile, replacement_value):\n",
    "    # Calcular el percentil de las frecuencias\n",
    "    frequencies = data[column].value_counts()\n",
    "    threshold = np.percentile(frequencies, percentile)\n",
    "    \n",
    "    # Crear una copia del DataFrame para evitar modificar el original\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Reemplazar los valores en las filas donde la frecuencia es menor al percentil dado\n",
    "    data_copy.loc[data_copy[column].map(frequencies) < threshold, column] = replacement_value\n",
    "    \n",
    "    return data_copy\n",
    "\n",
    "modified_data = replace_by_percentile(general_data, \"DESCRIPCION_CONDUCTA_CAPTURA\", 88, \"OTROS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un nuevo conjunto de datos ajustado según la geolocalización. Primero, convierte a Bogotá en un departamento independiente cambiando su nombre en las columnas correspondientes y eliminando duplicados. Luego, renombra ciertos departamentos para que tengan sus nombres completos, como \"La Guajira\" y \"Valle del Cauca\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un nuevo datasets, con los datos ajustados a la geolocalizacion\n",
    "clean_data = modified_data.copy()\n",
    "\n",
    "# Primero convertimos bogota en un departamento independiente\n",
    "bogota_dc = modified_data[modified_data[\"MUNICIPIO\"] == \"BOGOTÁ D.C.\"]\n",
    "bogota_dc.loc[:, \"DEPARTAMENTO\"] = \"BOGOTÁ, D.C.\"\n",
    "bogota_dc.loc[:, \"MUNICIPIO\"] = \"BOGOTÁ, D.C.\"\n",
    "clean_data = pd.concat([clean_data, bogota_dc], ignore_index=True)\n",
    "clean_data = clean_data[clean_data[\"MUNICIPIO\"] != \"BOGOTÁ D.C.\"]\n",
    "\n",
    "#Renombramos guajira a la guajira\n",
    "clean_data.loc[clean_data[\"DEPARTAMENTO\"] == \"GUAJIRA\", \"DEPARTAMENTO\"] = \"LA GUAJIRA\"\n",
    "#Renombramos valle a valle del cauca\n",
    "clean_data.loc[clean_data[\"DEPARTAMENTO\"] == \"VALLE\", \"DEPARTAMENTO\"] = \"VALLE DEL CAUCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que convierte nombres de municipios a sus formas oficiales o completas usando un diccionario de correspondencia. Si un nombre está en el diccionario, se reemplaza; si no, se mantiene igual. Luego, aplica esta función a la columna de municipios en el conjunto de datos clean_data.</br>**Cambia los nombres de los municipios, por sus nombres oficiales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_names(original_names):\n",
    "    # Diccionario de correspondencia entre los nombres\n",
    "    dictionary  = {\n",
    "        'CALI': 'SANTIAGO DE CALI',\n",
    "        'LÓPEZ': 'LÓPEZ DE MICAY',\n",
    "        'EL PAUJIL': 'EL PAUJÍL',\n",
    "        'MAGÜI': 'MAGÜÍ',\n",
    "        'CARTAGENA': 'CARTAGENA DE INDIAS',\n",
    "        'SOTARA': 'SOTARÁ PAISPAMBA',\n",
    "        'GACHALA': 'GACHALÁ',\n",
    "        'PURÍSIMA': 'PURÍSIMA DE LA CONCEPCIÓN',\n",
    "        'ANCUYÁ': 'ANCUYA',\n",
    "        'CERRO SAN ANTONIO': 'CERRO DE SAN ANTONIO',\n",
    "        'MARIQUITA': 'SAN SEBASTIÁN DE MARIQUITA',\n",
    "        'SANTAFÉ DE ANTIOQUIA': 'SANTA FÉ DE ANTIOQUIA',\n",
    "        'ITAGUI': 'ITAGÜÍ',\n",
    "        'CACHIRÁ': 'CÁCHIRA',\n",
    "        'ANZA': 'ANZÁ',\n",
    "        'CARMEN DEL DARIEN': 'CARMEN DEL DARIÉN',\n",
    "        'CUASPUD': 'CUASPUD CARLOSAMA',\n",
    "        'COLOSO': 'COLOSÓ',\n",
    "        'SAN ANDRÉS SOTAVENTO': 'SAN ANDRÉS DE SOTAVENTO',\n",
    "        'SAN JUAN DE RÍO SECO': 'SAN JUAN DE RIOSECO',\n",
    "        'GÜICÁN': 'GÜICÁN DE LA SIERRA',\n",
    "        'SABANAS DE SAN ANGEL': 'SABANAS DE SAN ÁNGEL',\n",
    "        'CAQUEZA': 'CÁQUEZA',\n",
    "        'MOMPÓS': 'SANTA CRUZ DE MOMPOX',\n",
    "        'CHAMEZA': 'CHÁMEZA',\n",
    "        'CARURU': 'CARURÚ',\n",
    "        'BELÉN DE LOS ANDAQUIES': 'BELÉN DE LOS ANDAQUÍES',\n",
    "        'CONSACA': 'CONSACÁ',\n",
    "        'CÚCUTA': 'SAN JOSÉ DE CÚCUTA',\n",
    "        'GAMBITA': 'GÁMBITA',\n",
    "        'ENTRERRIOS': 'ENTRERRÍOS',\n",
    "        'TORIBIO': 'TORIBÍO',\n",
    "        'SAN ANDRES DE TUMACO': 'SAN ANDRÉS DE TUMACO',\n",
    "        'RÍO IRO': 'RÍO IRÓ',\n",
    "        'EL PIÑON': 'EL PIÑÓN',\n",
    "        'SONSON': 'SONSÓN',\n",
    "        'MACHETA': 'MACHETÁ',\n",
    "        'CALARCA': 'CALARCÁ',\n",
    "        'TURBANÁ': 'TURBANA',\n",
    "        'UMBITA': 'ÚMBITA',\n",
    "        'GUAYABAL DE SIQUIMA': 'GUAYABAL DE SÍQUIMA',\n",
    "        'GAMEZA': 'GÁMEZA',\n",
    "        'IQUIRA': 'ÍQUIRA',\n",
    "        'PIENDAMÓ': 'PIENDAMÓ - TUNÍA',\n",
    "        'ABREGO': 'ÁBREGO',\n",
    "        'SAN VICENTE': 'SAN VICENTE FERRER',\n",
    "        'VILLA DE SAN DIEGO DE UBATE': 'VILLA DE SAN DIEGO DE UBATÉ',\n",
    "        'DON MATÍAS': 'DONMATÍAS',\n",
    "        'FOMEQUE': 'FÓMEQUE'\n",
    "    }\n",
    "\n",
    "    # Convertir los nombres utilizando el diccionario, o mantener el nombre original si no se encuentra\n",
    "    converted_names = [dictionary.get(name, name) for name in original_names]\n",
    "    \n",
    "    return converted_names\n",
    "\n",
    "\n",
    "# Aplicar la función a la columna 'MUNICIPIO' del DataFrame clean_data\n",
    "clean_data['MUNICIPIO'] = convert_names (clean_data['MUNICIPIO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga un archivo JSON con datos geográficos de Colombia, ajusta los nombres de las columnas y elimina una columna innecesaria. Luego, fusiona estos datos con el conjunto de datos clean_data, filtra los registros relacionados con un delito específico, agrupa los datos por mes, departamento, municipio y coordenadas geográficas, y calcula la suma de los valores. Finalmente, extrae el mes de la fecha y organiza las columnas relevantes para obtener un conjunto de datos mensual con información geográfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf = pd.read_json(\"GeoColombia.json\") \\\n",
    "    .rename(columns={\"Departamento\": \"DEPARTAMENTO\", \"Localidad\": \"MUNICIPIO\"}) \\\n",
    "    .drop(columns=[\"Tipo\"])\n",
    "\n",
    "monthly_data = pd.merge(clean_data, geodf, on=[\"DEPARTAMENTO\", \"MUNICIPIO\"], how=\"inner\") \\\n",
    "    .query(\"DESCRIPCION_CONDUCTA_CAPTURA == 'ARTÍCULO 376. TRÁFICO. FABRICACIÓN O PORTE DE ESTUPEFACIENTES'\") \\\n",
    "    .groupby([pd.Grouper(key='FECHA_HECHO', freq='ME'), 'DEPARTAMENTO', 'MUNICIPIO', 'LATITUD', 'LONGITUD']) \\\n",
    "    .sum() \\\n",
    "    .reset_index()\n",
    "\n",
    "monthly_data['MES'] = monthly_data['FECHA_HECHO'].dt.to_period('M')\n",
    "monthly_data = monthly_data[['MES', 'LATITUD', 'LONGITUD', 'CANTIDAD ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copia los datos mensuales y luego crea una nueva columna llamada 'lat_long', que combina las coordenadas de latitud y longitud con un formato específico para cumplir con las reglas de MATLAB. Se reemplazan los puntos por 'p' y los signos negativos por 'n'. Después, pivota el DataFrame para organizar los datos de manera que cada combinación única de mes y coordenadas se convierta en una columna, con los valores de la columna 'CANTIDAD' sumados cuando es necesario y los valores faltantes llenados con ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar los datos mensuales\n",
    "df = monthly_data.copy()\n",
    "\n",
    "# Crear la columna 'lat_long' con un prefijo y reemplazar el separador para cumplir con las reglas de MATLAB\n",
    "df['lat_long'] = (\n",
    "    'loc_' +\n",
    "    df['LATITUD'].astype(str).str.replace('.', 'p').str.replace('-', 'n') + # Reemplaza '.' con 'p' y '-' con 'n'\n",
    "    'x' +\n",
    "    df['LONGITUD'].astype(str).str.replace('.', 'p').str.replace('-', 'n')\n",
    ")\n",
    "\n",
    "# Pivotar el DataFrame\n",
    "df_pivot = df.pivot_table(index='MES', columns='lat_long', values='CANTIDAD ', aggfunc='sum', fill_value=0)\n",
    "df_pivot.to_csv(\"resultado_pivot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga un archivo CSV con los datos previamente pivotados y luego deshace el pivot (convierte las columnas 'lat_long' de nuevo en filas). Después, separa la columna 'lat_long' en dos nuevas columnas: 'LATITUD' y 'LONGITUD'. Los valores de estas columnas se ajustan reemplazando caracteres que fueron usados para formatear las coordenadas (como 'n' por '-' y 'p' por '.') para restaurar los valores numéricos originales. También elimina el prefijo 'loc_' y convierte las columnas 'LATITUD' y 'LONGITUD' a tipo numérico. Finalmente, elimina la columna 'lat_long' que ya no es necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Despivotar el DataFrame (convertir las columnas 'lat_long' en filas)\n",
    "df_pivot = pd.read_csv('resultado_pivot.csv')\n",
    "# Despivotar el DataFrame\n",
    "df_unpivoted = pd.melt(df_pivot, id_vars=['MES'], var_name='lat_long', value_name='CANTIDAD')\n",
    "\n",
    "# Separar la columna 'lat_long' en 'LATITUD' y 'LONGITUD'\n",
    "df_unpivoted[['LATITUD', 'LONGITUD']] = df_unpivoted['lat_long'].str.split('x', expand=True)\n",
    "\n",
    "# Reemplazar 'n' con '-' y 'p' con '.' para recuperar los valores numéricos originales\n",
    "df_unpivoted['LATITUD'] = df_unpivoted['LATITUD'].str.replace('n', '-', regex=False).str.replace('p', '.', regex=False)\n",
    "df_unpivoted['LONGITUD'] = df_unpivoted['LONGITUD'].str.replace('n', '-', regex=False).str.replace('p', '.', regex=False)\n",
    "\n",
    "# Eliminar el prefijo 'loc_' de las coordenadas\n",
    "df_unpivoted['LATITUD'] = df_unpivoted['LATITUD'].str.replace('loc_', '', regex=False)\n",
    "df_unpivoted['LONGITUD'] = df_unpivoted['LONGITUD'].str.replace('loc_', '', regex=False)\n",
    "\n",
    "# Convertir las columnas LATITUD y LONGITUD a tipo numérico\n",
    "df_unpivoted['LATITUD'] = pd.to_numeric(df_unpivoted['LATITUD'])\n",
    "df_unpivoted['LONGITUD'] = pd.to_numeric(df_unpivoted['LONGITUD'])\n",
    "\n",
    "# Eliminar la columna 'lat_long' ya que ahora tenemos LATITUD y LONGITUD\n",
    "df_unpivoted.drop(columns=['lat_long'], inplace=True)\n",
    "df_unpivoted['CANTIDAD'] = df_unpivoted['CANTIDAD'].round(0).astype(int)\n",
    "df_unpivoted[df_unpivoted[\"CANTIDAD\"] > 0].to_csv('resultado_unpivot_rounded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define una función que toma un conjunto de datos y los filtra según una columna específica (en este caso, \"DEPARTAMENTO\"). Luego, para cada valor único en esa columna, crea un archivo CSV con los datos correspondientes. La función también asegura que la carpeta donde se guardarán los archivos exista, y si no, la crea automáticamente. Para cada archivo generado, imprime el nombre del archivo y la cantidad de filas que contiene, aunque esta opción de impresión puede ser desactivada si se desea. Finalmente, la función guarda los archivos CSV en la carpeta especificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Función para guardar un archivo CSV por cada valor único en una columna\n",
    "# data: DataFrame con los datos\n",
    "# filter_column: nombre de la columna a utilizar para filtrar los datos\n",
    "# output_folder: carpeta donde guardar los archivos CSV\n",
    "# out: si es True, imprime un mensaje al guardar cada archivo CSV\n",
    "def csv_by_filter(data, filter_column, output_folder, out = True):\n",
    "    # Especifica la carpeta donde guardar los archivos CSV\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Crea la carpeta si no existe\n",
    "\n",
    "    # Filtra y guarda un CSV para cada departamento\n",
    "    for filter_column, loop_data in data.groupby(filter_column):\n",
    "        # Genera el nombre del archivo para cada departamento\n",
    "        output_file = os.path.join(output_folder, f\"{filter_column}.csv\")\n",
    "        if (out):\n",
    "            print(f\"Guardando {output_file}... con {len(loop_data)} filas\")\n",
    "        # Guarda el DataFrame filtrado como CSV\n",
    "        loop_data.to_csv(output_file, index=False)\n",
    "    if (out):\n",
    "        print(\"Archivos CSV generados en la carpeta:\", output_folder)\n",
    "\n",
    "# Filtra y guarda un CSV para cada departamento\n",
    "csv_by_filter(modified_data, \"DEPARTAMENTO\", 'CSV por Departamento', out = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series de tiempo, graficas de correlacion, graficas de correlacion parcial y graficos de dipsersion por lag (retardo) para departamentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "cundinamarca = pd.read_csv('CSV por Departamento/CUNDINAMARCA.csv')\n",
    "\n",
    "# Convertir la columna de fechas a datetime para trabajar con series de tiempo\n",
    "cundinamarca['FECHA_HECHO'] = pd.to_datetime(cundinamarca['FECHA_HECHO'])\n",
    "cundinamarca = cundinamarca.set_index('FECHA_HECHO')  # Configura el índice del DataFrame como fecha\n",
    "\n",
    "# Función para cambiar la escala de la serie de tiempo\n",
    "def cambiar_escala(df, escala='D', columna_valores=None):\n",
    "    \"\"\"\n",
    "    Cambia la escala de tiempo de la serie.\n",
    "    Parámetros:\n",
    "        df: DataFrame original con índice de fechas\n",
    "        escala: Frecuencia deseada ('D' para diaria, 'W' para semanal, 'M' para mensual, '2M' para bimestral,\n",
    "                'Q' para trimestral, '6M' para semestral, 'Y' para anual)\n",
    "        columna_valores: Columna a agregar como serie. Si es None, se usa el conteo de registros por fecha.\n",
    "    \"\"\"\n",
    "    if columna_valores:\n",
    "        serie = df[columna_valores].resample(escala).sum()\n",
    "    else:\n",
    "        serie = df.resample(escala).size()  # Cuenta de eventos en cada intervalo de tiempo\n",
    "    return serie\n",
    "\n",
    "# Selecciona la escala de tiempo deseada\n",
    "escala = 'ME'  # Cambia a 'D', 'W', '2M', 'Q', '6M', 'Y' para diferentes escalas (diario, semanal, etc.)\n",
    "columna_valores = None  # Si tienes una columna específica para sumar, cambia aquí su nombre\n",
    "\n",
    "# Cambia la escala de la serie de tiempo\n",
    "serie = cambiar_escala(cundinamarca, escala=escala, columna_valores=columna_valores)\n",
    "\n",
    "# Visualización de la serie de tiempo con la escala seleccionada\n",
    "fig = px.line(serie, title=f\"Serie de Tiempo con Escala {escala}\")\n",
    "fig.update_xaxes(title_text=\"Fecha\")\n",
    "fig.update_yaxes(title_text=\"Valores\")\n",
    "fig.show()\n",
    "\n",
    "# Parámetros de autocorrelación\n",
    "num_lags = 30  # Ajusta el número de rezagos que deseas visualizar en los gráficos de ACF y PACF\n",
    "\n",
    "# Cálculo de ACF y PACF\n",
    "acf_vals = acf(serie, nlags=num_lags, alpha=0.05)  # alpha para el intervalo de confianza\n",
    "pacf_vals = pacf(serie, nlags=num_lags)\n",
    "lags = list(range(num_lags + 1))\n",
    "\n",
    "# Gráfico de Autocorrelación (ACF) con intervalos de confianza\n",
    "fig_acf = go.Figure()\n",
    "\n",
    "# Añadir la traza de ACF\n",
    "fig_acf.add_trace(go.Bar(x=lags, y=acf_vals[0], name=\"ACF\", marker_color=\"blue\"))\n",
    "\n",
    "# Calcular intervalos de confianza\n",
    "conf_int = 1.96 / np.sqrt(len(serie))  # 95% de confianza\n",
    "\n",
    "# Añadir líneas de intervalo de confianza\n",
    "fig_acf.add_trace(go.Scatter(x=lags, y=acf_vals[0] + conf_int, mode='lines', name='Upper CI', line=dict(color='red', dash='dash')))\n",
    "fig_acf.add_trace(go.Scatter(x=lags, y=acf_vals[0] - conf_int, mode='lines', name='Lower CI', line=dict(color='red', dash='dash')))\n",
    "\n",
    "fig_acf.update_layout(title=\"Gráfico de Autocorrelación (ACF)\",\n",
    "                      xaxis_title=\"Rezagos (Lags)\",\n",
    "                      yaxis_title=\"Autocorrelación\")\n",
    "fig_acf.show()\n",
    "\n",
    "# Gráfico de Autocorrelación Parcial (PACF)\n",
    "fig_pacf = go.Figure()\n",
    "fig_pacf.add_trace(go.Bar(x=lags, y=pacf_vals, name=\"PACF\", marker_color=\"orange\"))\n",
    "fig_pacf.update_layout(title=\"Gráfico de Autocorrelación Parcial (PACF)\",\n",
    "                       xaxis_title=\"Rezagos (Lags)\",\n",
    "                       yaxis_title=\"Autocorrelación Parcial\")\n",
    "fig_pacf.show()\n",
    "\n",
    "# Gráficos de dispersión para cada retraso (lag)\n",
    "num_lags_scatter = 12  # Selecciona cuántos lags deseas graficar\n",
    "for lag in range(1, num_lags_scatter + 1):\n",
    "    # Crear serie desplazada\n",
    "    serie_lagged = serie.shift(lag)\n",
    "    \n",
    "    # Crear la figura para cada lag\n",
    "    fig = px.scatter(x=serie_lagged, y=serie, title=f'Gráfico de Dispersión para Lag {lag}')\n",
    "    fig.update_xaxes(title_text=f'Valores Rezagados (Lag {lag})')\n",
    "    fig.update_yaxes(title_text='Valores Actuales')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## series de tiempo desglosadas por municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Cargar y preparar los datos\n",
    "cundinamarca = pd.read_csv(\"CSV por Departamento/CAUCA.csv\")\n",
    "cundinamarca['FECHA_HECHO'] = pd.to_datetime(cundinamarca['FECHA_HECHO'])\n",
    "\n",
    "# Función para cambiar la escala temporal de la serie\n",
    "def cambiar_escala(df, escala='ME', columna_fecha='FECHA_HECHO', columna_valores='CANTIDAD'):\n",
    "    df = df.set_index(columna_fecha)\n",
    "    serie = df[columna_valores].resample(escala).sum()\n",
    "    return serie\n",
    "\n",
    "# Definir la escala de tiempo deseada y el número de lags\n",
    "escala = 'ME'  # Escala temporal: 'D' para diario, 'W' para semanal, 'ME' para mensual, etc.\n",
    "num_lags = 30  # Número de lags para ACF y PACF\n",
    "\n",
    "# Lista de municipios\n",
    "municipios = cundinamarca['MUNICIPIO'].unique()\n",
    "\n",
    "# Gráfico de series de tiempo, ACF, PACF para cada municipio\n",
    "for municipio in municipios:\n",
    "    datos_municipio = cundinamarca[cundinamarca['MUNICIPIO'] == municipio]  # Filtrar datos por municipio\n",
    "    serie_municipio = cambiar_escala(datos_municipio, escala=escala)  # Cambiar la escala temporal\n",
    "    \n",
    "    # Gráfico de la serie de tiempo\n",
    "    fig_tiempo = px.line(serie_municipio, title=f\"Serie de Tiempo - {municipio}\", labels={\"value\": \"Cantidad\", \"FECHA_HECHO\": \"Fecha\"})\n",
    "    fig_tiempo.update_layout(xaxis_title=\"Fecha\", yaxis_title=\"Cantidad de Delitos\")\n",
    "    fig_tiempo.show()\n",
    "    \n",
    "    # Cálculo de ACF y PACF\n",
    "    acf_vals = acf(serie_municipio, nlags=num_lags)\n",
    "    pacf_vals = pacf(serie_municipio, nlags=num_lags)\n",
    "    lags = list(range(num_lags + 1))\n",
    "\n",
    "    # Gráfico de Autocorrelación (ACF) con intervalo de confianza\n",
    "    fig_acf = go.Figure()\n",
    "    fig_acf.add_trace(go.Bar(x=lags, y=acf_vals, name=\"ACF\"))\n",
    "    conf_interval_acf = 1.96 / (len(serie_municipio) ** 0.5)\n",
    "    fig_acf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=conf_interval_acf, y1=conf_interval_acf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "    fig_acf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=-conf_interval_acf, y1=-conf_interval_acf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "    fig_acf.update_layout(title=f\"Gráfico de Autocorrelación (ACF) - {municipio}\",\n",
    "                          xaxis_title=\"Rezagos (Lags)\",\n",
    "                          yaxis_title=\"Autocorrelación\")\n",
    "    fig_acf.show()\n",
    "\n",
    "    # Gráfico de Autocorrelación Parcial (PACF)\n",
    "    fig_pacf = go.Figure()\n",
    "    fig_pacf.add_trace(go.Bar(x=lags, y=pacf_vals, name=\"PACF\", marker_color=\"orange\"))\n",
    "    conf_interval_pacf = 1.96 / (len(serie_municipio) ** 0.5)\n",
    "    fig_pacf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=conf_interval_pacf, y1=conf_interval_pacf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "    fig_pacf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=-conf_interval_pacf, y1=-conf_interval_pacf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "    fig_pacf.update_layout(title=f\"Gráfico de Autocorrelación Parcial (PACF) - {municipio}\",\n",
    "                           xaxis_title=\"Rezagos (Lags)\",\n",
    "                           yaxis_title=\"Autocorrelación Parcial\")\n",
    "    fig_pacf.show()\n",
    "\n",
    "    # Función opcional para gráficos de dispersión de lags (comentada)\n",
    "    \n",
    "    # Gráficos de dispersión para diferentes lags\n",
    "    def graficar_lag_disperion(serie, max_lag):\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            fig_lag = px.scatter(x=serie[:-lag], y=serie[lag:], title=f\"Gráfico de Dispersión - Retardo {lag}\",\n",
    "                                 labels={\"x\": f\"Valor en t\", \"y\": f\"Valor en t + {lag}\"})\n",
    "            fig_lag.update_layout(xaxis_title=\"Valor en t\", yaxis_title=f\"Valor en t + {lag}\")\n",
    "            fig_lag.show()\n",
    "    \n",
    "    # Llamada a la función para graficar dispersión de lags hasta el número deseado\n",
    "    graficar_lag_disperion(serie_municipio.values, max_lag=1)  # Cambia max_lag según el número de lags deseado\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# selecciona un departamento y un municipio en espescifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Cargar y preparar los datos\n",
    "data = pd.read_csv(\"CSV por Departamento/CAUCA.csv\")\n",
    "data['FECHA_HECHO'] = pd.to_datetime(data['FECHA_HECHO'])\n",
    "\n",
    "# Variables de selección para el departamento y municipio\n",
    "departamento = \"CAUCA\"\n",
    "municipio_seleccionado = \"ROSAS\"\n",
    "\n",
    "# Filtrar datos por el departamento y municipio deseados\n",
    "data_filtrada = data[(data['DEPARTAMENTO'] == departamento) & (data['MUNICIPIO'] == municipio_seleccionado)]\n",
    "\n",
    "# Función para cambiar la escala temporal de la serie\n",
    "def cambiar_escala(df, escala='ME', columna_fecha='FECHA_HECHO', columna_valores='CANTIDAD'):\n",
    "    df = df.set_index(columna_fecha)\n",
    "    serie = df[columna_valores].resample(escala).sum()\n",
    "    return serie\n",
    "\n",
    "# Definir la escala de tiempo deseada y el número de lags\n",
    "escala = 'ME'  # Escala temporal: 'D' para diario, 'W' para semanal, 'ME' para mensual, etc.\n",
    "num_lags = 30  # Número de lags para ACF y PACF\n",
    "\n",
    "# Cambiar la escala temporal para el municipio seleccionado\n",
    "serie_municipio = cambiar_escala(data_filtrada, escala=escala)\n",
    "\n",
    "# Gráfico de la serie de tiempo\n",
    "fig_tiempo = px.line(serie_municipio, title=f\"Serie de Tiempo - {municipio_seleccionado}\", labels={\"value\": \"Cantidad\", \"FECHA_HECHO\": \"Fecha\"})\n",
    "fig_tiempo.update_layout(xaxis_title=\"Fecha\", yaxis_title=\"Cantidad de Delitos\")\n",
    "fig_tiempo.show()\n",
    "\n",
    "# Cálculo de ACF y PACF\n",
    "acf_vals = acf(serie_municipio, nlags=num_lags)\n",
    "pacf_vals = pacf(serie_municipio, nlags=num_lags)\n",
    "lags = list(range(num_lags + 1))\n",
    "\n",
    "# Gráfico de Autocorrelación (ACF) con intervalo de confianza\n",
    "fig_acf = go.Figure()\n",
    "fig_acf.add_trace(go.Bar(x=lags, y=acf_vals, name=\"ACF\"))\n",
    "conf_interval_acf = 1.96 / (len(serie_municipio) ** 0.5)\n",
    "fig_acf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=conf_interval_acf, y1=conf_interval_acf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "fig_acf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=-conf_interval_acf, y1=-conf_interval_acf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "fig_acf.update_layout(title=f\"Gráfico de Autocorrelación (ACF) - {municipio_seleccionado}\",\n",
    "                      xaxis_title=\"Rezagos (Lags)\",\n",
    "                      yaxis_title=\"Autocorrelación\")\n",
    "fig_acf.show()\n",
    "\n",
    "# Gráfico de Autocorrelación Parcial (PACF)\n",
    "fig_pacf = go.Figure()\n",
    "fig_pacf.add_trace(go.Bar(x=lags, y=pacf_vals, name=\"PACF\", marker_color=\"orange\"))\n",
    "conf_interval_pacf = 1.96 / (len(serie_municipio) ** 0.5)\n",
    "fig_pacf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=conf_interval_pacf, y1=conf_interval_pacf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "fig_pacf.add_shape(type=\"line\", x0=0, x1=num_lags, y0=-conf_interval_pacf, y1=-conf_interval_pacf, line=dict(color=\"red\", dash=\"dash\"))\n",
    "fig_pacf.update_layout(title=f\"Gráfico de Autocorrelación Parcial (PACF) - {municipio_seleccionado}\",\n",
    "                       xaxis_title=\"Rezagos (Lags)\",\n",
    "                       yaxis_title=\"Autocorrelación Parcial\")\n",
    "fig_pacf.show()\n",
    "\n",
    "# Función para gráficos de dispersión de lags\n",
    "def graficar_lag_dispersion(serie, max_lag):\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        fig_lag = px.scatter(x=serie[:-lag], y=serie[lag:], title=f\"Gráfico de Dispersión - Retardo {lag}\",\n",
    "                             labels={\"x\": f\"Valor en t\", \"y\": f\"Valor en t + {lag}\"})\n",
    "        fig_lag.update_layout(xaxis_title=\"Valor en t\", yaxis_title=f\"Valor en t + {lag}\")\n",
    "        fig_lag.show()\n",
    "\n",
    "# Llamada a la función para graficar dispersión de lags hasta el número deseado\n",
    "graficar_lag_dispersion(serie_municipio.values, max_lag=3)  # Ajusta max_lag según el número de lags deseado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "cundinamarca = pd.read_csv('CSV por Departamento/CAUCA.csv')\n",
    "\n",
    "# Convertir la columna de fechas a datetime para trabajar con series de tiempo\n",
    "cundinamarca['FECHA_HECHO'] = pd.to_datetime(cundinamarca['FECHA_HECHO'])\n",
    "cundinamarca = cundinamarca.set_index('FECHA_HECHO')  # Configura el índice del DataFrame como fecha\n",
    "\n",
    "# Función para cambiar la escala de la serie de tiempo y desglosar por genero\n",
    "def cambiar_escala_por_genero(df, escala='M', columna_valores='CANTIDAD', columna_genero='GENERO'):\n",
    "    \"\"\"\n",
    "    Cambia la escala de tiempo de la serie y desglosa por género.\n",
    "    Parámetros:\n",
    "        df: DataFrame original con índice de fechas\n",
    "        escala: Frecuencia deseada ('D' para diaria, 'W' para semanal, 'M' para mensual, 'Q' para trimestral, 'Y' para anual)\n",
    "        columna_valores: Columna con valores numéricos\n",
    "        columna_genero: Columna que indica el género (masculino/femenino)\n",
    "    \"\"\"\n",
    "    # Agrupar por la frecuencia seleccionada y por género, sumando la cantidad de incidentes\n",
    "    serie = df.groupby([pd.Grouper(freq=escala), columna_genero])[columna_valores].sum().unstack()\n",
    "    return serie\n",
    "\n",
    "# Seleccionar escala y columna de valores\n",
    "escala = 'ME'  # Mensual\n",
    "columna_valores = 'CANTIDAD'\n",
    "\n",
    "# Cambia la escala de la serie de tiempo y desglosa por género\n",
    "serie_por_genero = cambiar_escala_por_genero(cundinamarca, escala=escala, columna_valores=columna_valores)\n",
    "\n",
    "# Visualización de la serie de tiempo con la escala seleccionada, desglosada por género\n",
    "fig = px.line(serie_por_genero, title=f\"Serie de Tiempo con Escala {escala} por Género\")\n",
    "fig.update_xaxes(title_text=\"Fecha\")\n",
    "fig.update_yaxes(title_text=\"Cantidad\")\n",
    "fig.show()\n",
    "\n",
    "# Parámetros de autocorrelación\n",
    "num_lags = 30\n",
    "\n",
    "# Cálculo de ACF y PACF por género\n",
    "for genero in serie_por_genero.columns:\n",
    "    serie = serie_por_genero[genero].dropna()  # Eliminar valores nulos\n",
    "\n",
    "    # Cálculo de ACF y PACF\n",
    "    acf_vals, acf_confint = acf(serie, nlags=num_lags, alpha=0.05)\n",
    "    pacf_vals = pacf(serie, nlags=num_lags)\n",
    "    lags = list(range(num_lags + 1))\n",
    "\n",
    "    # Gráfico de Autocorrelación (ACF) con intervalos de confianza\n",
    "    fig_acf = go.Figure()\n",
    "    fig_acf.add_trace(go.Bar(x=lags, y=acf_vals, name=\"ACF\", marker_color=\"blue\"))\n",
    "\n",
    "    for i in range(len(lags)):\n",
    "        fig_acf.add_shape(type=\"line\", x0=lags[i], x1=lags[i], y0=acf_confint[i, 0], y1=acf_confint[i, 1],\n",
    "                          line=dict(color=\"red\", dash=\"dash\"))\n",
    "\n",
    "    fig_acf.update_layout(title=f\"ACF - {genero}\",\n",
    "                          xaxis_title=\"Rezagos (Lags)\",\n",
    "                          yaxis_title=\"Autocorrelación\")\n",
    "    fig_acf.show()\n",
    "\n",
    "    # Gráfico de Autocorrelación Parcial (PACF)\n",
    "    fig_pacf = go.Figure()\n",
    "    fig_pacf.add_trace(go.Bar(x=lags, y=pacf_vals, name=\"PACF\", marker_color=\"orange\"))\n",
    "    fig_pacf.update_layout(title=f\"PACF - {genero}\",\n",
    "                           xaxis_title=\"Rezagos (Lags)\",\n",
    "                           yaxis_title=\"Autocorrelación Parcial\")\n",
    "    fig_pacf.show()\n",
    "    \n",
    "    # Gráfico de dispersión para los lags seleccionados\n",
    "    num_lags_scatter = 12\n",
    "    for lag in range(1, num_lags_scatter + 1):\n",
    "        serie_lagged = serie.shift(lag)\n",
    "        fig = px.scatter(x=serie_lagged, y=serie, title=f'Dispersión Lag {lag} - {genero}')\n",
    "        fig.update_xaxes(title_text=f'Valores Rezagados (Lag {lag})')\n",
    "        fig.update_yaxes(title_text='Valores Actuales')\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos\n",
    "meses = [\n",
    "    \"Enero\", \"Febrero\", \"Marzo\", \"Abril\", \"Mayo\", \"Junio\",\n",
    "    \"Julio\", \"Agosto\", \"Septiembre\", \"Octubre\", \"Noviembre\", \"Diciembre\"\n",
    "]\n",
    "factores_estacionales = [\n",
    "    0.9052, 1.0289, 1.0187, 1.0486, 1.0436, 0.5776,\n",
    "    0.8616, 1.2293, 1.3710, 0.9078, 0.9841, 0.9670\n",
    "]\n",
    "\n",
    "# Paleta de colores personalizada\n",
    "colores = [\"#ff9999\", \"#66b3ff\", \"#99ff99\", \"#ffcc99\", \"#c2c2f0\", \"#ffb3e6\",\n",
    "           \"#c4e17f\", \"#76d7c4\", \"#f7b7a3\", \"#f4a261\", \"#e9c46a\", \"#2a9d8f\"]\n",
    "\n",
    "# Crear gráfico de dona\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(factores_estacionales, labels=meses, colors=colores, autopct='%1.1f%%', startangle=90, pctdistance=0.85)\n",
    "\n",
    "# Crear el círculo interno para hacer el gráfico de dona\n",
    "centro = plt.Circle((0, 0), 0.70, fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centro)\n",
    "\n",
    "# Título\n",
    "plt.title('Factor Estacional por Mes')\n",
    "\n",
    "# Guardar el gráfico como PNG\n",
    "plt.savefig(\"grafico_dona.png\", format=\"png\", dpi=300)\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
